# **LLaMA**


### **Papers**  
I am reading these papers:
- [ ] [LLaMA: Open and Efficient Foundation Language Models](https://ai.meta.com/research/publications/llama-open-and-efficient-foundation-language-models/)
- [ ] [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)

### **Goals**
- [ ] Understand and implement grouped query attention from scratch.
- [ ] Understand and implement the concept of KV cache.
- [ ] Understand and implement the rotatory positional encoding.
- [ ] Adding ...
